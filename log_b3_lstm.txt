2025-12-31 04:53:25.990053: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-31 04:53:30.876827: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
======================================================================
BASELINE: EFFICIENTNET-B3 + SIMPLE LSTM
======================================================================
Device: cuda
Model: EfficientNet-B3
Input Size: 300�300
Feature Map: 10�10�1536
Num Regions: 100
Feature Dim: 1536
----------------------------------------------------------------------
Batch Size: 32
Epochs: 50
Learning Rate: 1e-04
----------------------------------------------------------------------
Embed Size: 512
Hidden Size: 512
----------------------------------------------------------------------
Attention: DISABLED
Scheduled Sampling: DISABLED
======================================================================
Loaded features for 8091 images (4741.4 MB)

Loading captions...
Loaded captions for 8091 images
Cleaning captions...
Building vocabulary (min_freq=1)...
Vocab size: 8369
Max caption length: 34
Rare words filtered: 0 (0.0% of tokens)
Train images: 6472, Test images: 1619
Train batches: 1012, Val batches: 253
Total params: 15,661,745, Trainable: 15,661,745
C:\Users\LAPTOP\anaconda3\envs\fer\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(

======================================================================
STARTING TRAINING
======================================================================


Epoch 1/50 [Train]: 100%|##########| 1012/1012 [02:36<00:00,  6.46it/s, loss=5.3330]
Epoch 1/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 31.89it/s, loss=5.1453]

Epoch 1/50
Train Loss: 5.8862 | Val Loss: 5.2114
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 5.2114


Epoch 2/50 [Train]: 100%|##########| 1012/1012 [02:36<00:00,  6.48it/s, loss=5.4194]
Epoch 2/50 [Val]: 100%|##########| 253/253 [00:08<00:00, 30.82it/s, loss=4.7988]

Epoch 2/50
Train Loss: 5.1466 | Val Loss: 4.8615
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.8615


Epoch 3/50 [Train]: 100%|##########| 1012/1012 [02:36<00:00,  6.47it/s, loss=4.5753]
Epoch 3/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.23it/s, loss=4.5665]

Epoch 3/50
Train Loss: 4.8653 | Val Loss: 4.6536
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.6536


Epoch 4/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.52it/s, loss=4.4791]
Epoch 4/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 32.77it/s, loss=4.4591]

Epoch 4/50
Train Loss: 4.6765 | Val Loss: 4.5301
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.5301


Epoch 5/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.49it/s, loss=4.4639]
Epoch 5/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.04it/s, loss=4.3769]

Epoch 5/50
Train Loss: 4.5368 | Val Loss: 4.4416
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.4416


Epoch 6/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.55it/s, loss=4.1857]
Epoch 6/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.73it/s, loss=4.3166]

Epoch 6/50
Train Loss: 4.4276 | Val Loss: 4.3908
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.3908


Epoch 7/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.55it/s, loss=4.2924]
Epoch 7/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.08it/s, loss=4.2575]

Epoch 7/50
Train Loss: 4.3347 | Val Loss: 4.3379
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.3379


Epoch 8/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.56it/s, loss=4.1580]
Epoch 8/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.57it/s, loss=4.2212]

Epoch 8/50
Train Loss: 4.2576 | Val Loss: 4.3058
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.3058


Epoch 9/50 [Train]: 100%|##########| 1012/1012 [02:33<00:00,  6.58it/s, loss=4.3066]

Epoch 9/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.50it/s, loss=4.2035]

Epoch 9/50
Train Loss: 4.1897 | Val Loss: 4.2757
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2757


Epoch 10/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.49it/s, loss=4.4608]
Epoch 10/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.28it/s, loss=4.1796]

Epoch 10/50
Train Loss: 4.1243 | Val Loss: 4.2557
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2557


Epoch 11/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.50it/s, loss=3.8641]
Epoch 11/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 32.75it/s, loss=4.1826]

Epoch 11/50
Train Loss: 4.0698 | Val Loss: 4.2462
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2462


Epoch 12/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.49it/s, loss=4.3541]
Epoch 12/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.24it/s, loss=4.1542]

Epoch 12/50
Train Loss: 4.0146 | Val Loss: 4.2369
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2369


Epoch 13/50 [Train]: 100%|##########| 1012/1012 [02:35<00:00,  6.52it/s, loss=4.4694]
Epoch 13/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.27it/s, loss=4.1851]

Epoch 13/50
Train Loss: 3.9645 | Val Loss: 4.2320
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2320


Epoch 14/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.53it/s, loss=3.6721]
Epoch 14/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.61it/s, loss=4.1676]

Epoch 14/50
Train Loss: 3.9172 | Val Loss: 4.2237
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
New best model! Val Loss: 4.2237


Epoch 15/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.53it/s, loss=4.1440]
Epoch 15/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.37it/s, loss=4.1712]

Epoch 15/50
Train Loss: 3.8752 | Val Loss: 4.2255
LR: 0.000100
No improvement for 1 epoch(s)


Epoch 16/50 [Train]: 100%|##########| 1012/1012 [02:33<00:00,  6.57it/s, loss=3.7568]
Epoch 16/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.30it/s, loss=4.1846]

Epoch 16/50
Train Loss: 3.8314 | Val Loss: 4.2266
LR: 0.000100
No improvement for 2 epoch(s)


Epoch 17/50 [Train]: 100%|##########| 1012/1012 [02:33<00:00,  6.57it/s, loss=3.7324]
Epoch 17/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.68it/s, loss=4.1954]

Epoch 17/50
Train Loss: 3.7822 | Val Loss: 4.2248
LR: 0.000070
No improvement for 3 epoch(s)


Epoch 18/50 [Train]: 100%|##########| 1012/1012 [02:34<00:00,  6.55it/s, loss=3.6621]
Epoch 18/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.72it/s, loss=4.1810]

Epoch 18/50
Train Loss: 3.7516 | Val Loss: 4.2265
LR: 0.000070
No improvement for 4 epoch(s)


Epoch 19/50 [Train]: 100%|##########| 1012/1012 [02:33<00:00,  6.58it/s, loss=3.3369]
Epoch 19/50 [Val]: 100%|##########| 253/253 [00:07<00:00, 33.62it/s, loss=4.2037]

Epoch 19/50
Train Loss: 3.7138 | Val Loss: 4.2322
LR: 0.000049
No improvement for 5 epoch(s)
Early stopping after 19 epochs

TRAINING COMPLETED


Training completed!
Best model saved at: .\content\clean_data_flickr8k\baseline_efficientnet_b3_simple_lstm.pth
C:\Users\LAPTOP\Documents\Code\Python\EfficientNet_Full_Flavor_Attention.py:899: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(paths['model'], map_location=Config.DEVICE)
Loaded best model from epoch 14 with val loss 4.2237


Research Evaluation: 100%|##########| 1619/1619 [00:49<00:00, 32.74it/s]

RESEARCH METRICS (BASELINE - NO ATTENTION)
==================================================
BLEU-1 (nltk): 0.4901
BLEU-2 (nltk): 0.3324
BLEU-3 (nltk): 0.2259
BLEU-4 (nltk): 0.1448
BLEU-1 (linear BP): 0.4888
BLEU-2 (linear BP): 0.3315
BLEU-3 (linear BP): 0.2253
BLEU-4 (linear BP): 0.1445
METEOR: 0.2915
Avg Pred Len: 7.6368
Avg Ref Len: 7.9228
Len Ratio: 0.9639
==================================================

============================================================
Image ID: 3343311201_eeb1a39def
ACTUAL CAPTIONS:
1. startseq an artist painting on small canvas endseq
2. startseq woman standing on lawn painting picture endseq
3. startseq woman wearing overalls standing at an easel painting picture endseq
4. startseq girl in blue coverall painting endseq
5. startseq the lady holds her paintbrush next to the artist easel endseq

PREDICTED (greedy):
woman in black and white hat and black coat is standing in front of white building

PREDICTED (beam size=3):
the woman is standing in front of large tent
============================================================


============================================================
Image ID: 3601843201_4809e66909
ACTUAL CAPTIONS:
1. startseq man racing on motorbike endseq
2. startseq motorcycle rider drives fast around curve on track endseq
3. startseq person wearing red and white uniform is racing motorcycle with the number 58 on it endseq
4. startseq red and white motorcycle is being ridden around bend on racetrack endseq
5. startseq red and white motorbike number 58 races around the track endseq

PREDICTED (greedy):
motorcyclist in race

PREDICTED (beam size=3):
man on motorcycle
============================================================


============================================================
Image ID: 3079341641_f65f6b0f8b
ACTUAL CAPTIONS:
1. startseq there are two small girls smiling in hallway endseq
2. startseq two little girls in hallway woman standing in the background endseq
3. startseq two sisters race through the hallways in the house endseq
4. startseq two small girls running down hallway endseq
5. startseq two young girls at play in home endseq

PREDICTED (greedy):
two young girls are standing in front of house

PREDICTED (beam size=3):
two young girls are standing in front of house
============================================================


Done.
